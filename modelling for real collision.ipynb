{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import folium\n",
    "from folium.plugins import AntPath, MousePosition\n",
    "from sklearn.utils import shuffle, resample\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, RepeatVector, GRU, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Python\\master thesis\\collision data\\final_dataset_collision.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['# Timestamp'] = pd.to_datetime(df['# Timestamp'])\n",
    "df = df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "original_data = df\n",
    "minutes_before_collision = 3\n",
    "plt.plot(df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision]['Longitude'],df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision]['Latitude'])\n",
    "plt.plot(df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision]['Longitude'],df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision]['Latitude'])\n",
    "for i in range(30):\n",
    "    if i%2 ==0 :\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue' \n",
    "    longs = [df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Longitude'],df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Longitude']]\n",
    "    lats = [df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Latitude'],df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Latitude']]\n",
    "    print(haversine_distance(df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Longitude'],df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Latitude'],df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Longitude'],df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision][i:i+1]['Latitude']))\n",
    "    plt.plot(longs,lats,alpha = 0.3,linewidth=0.4,color = color)\n",
    "# plt.plot(df[df['MMSI'] == 219021240]['Longitude'],df[df['MMSI'] == 219021240]['Latitude'],zorder=1)\n",
    "# plt.plot(df[df['MMSI'] == 232018267][50:147]['Longitude'],df[df['MMSI'] == 232018267][50:147]['Latitude'],zorder=2)\n",
    "# plt.scatter(df[df['MMSI'] == 219021240][-2:-1]['Longitude'],df[df['MMSI'] == 219021240][-2:-1]['Latitude'],200,color='red',marker=(10, 1, 0),zorder=3,)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET LOAD\n",
    "\n",
    "df = pd.read_csv(r\"D:\\Python\\master thesis\\collision data\\final_dataset_collision.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['# Timestamp'] = pd.to_datetime(df['# Timestamp'])\n",
    "df = df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "\n",
    "\n",
    "def diff_to_coord(y,X):\n",
    "    a = np.zeros_like(y)\n",
    "    for j in tqdm(range(a.shape[0])):\n",
    "        for i in range(a.shape[1]):\n",
    "            if i == 0:\n",
    "                a[j,i,0] = X[j,-1,0] - y[j,i,0]\n",
    "                a[j,i,1] = X[j,-1,1] - y[j,i,1]\n",
    "            else:\n",
    "                a[j,i,0] = a[j,i-1,0] - y[j,i,0]\n",
    "                a[j,i,1] = a[j,i-1,1] - y[j,i,1]\n",
    "    return a\n",
    "def sequences_from_collision(minutes_before_collision):\n",
    "    seq = []\n",
    "    seq.append(df[df['MMSI'] == 219021240.0][-(30+minutes_before_collision):-minutes_before_collision])\n",
    "    seq.append(df[df['MMSI']== 232018267.0][:147][-(30+minutes_before_collision):-minutes_before_collision])\n",
    "    seq = np.dstack(seq)\n",
    "    seq = np.rollaxis(seq,-1)\n",
    "    return seq\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "def euclidean_distance(lon1,lat1,lon2,lat2):\n",
    "    return math.sqrt((lon1-lon2)**2+(lat1-lat2)**2)\n",
    "\n",
    "seq = sequences_from_collision(3)\n",
    "\n",
    "bad_sequences = []\n",
    "for index,i in tqdm(enumerate(seq)):\n",
    "    # print(index)\n",
    "    if 0 in i[:,4] or (i[:,6] > 2).sum() > 0 or (i[:,6] < 1).sum() > 0 or 0 in (np.append(np.atleast_2d(i[:,7:9].sum(axis=1)).T,i[:,7:8],axis=1)).sum(axis=1) or np.isnan((i[:,2:].astype(np.float32))).sum() > 0 or (i[:,11] <= 0).sum() > 0 or (i[:,11] > 800).sum() > 0:\n",
    "        bad_sequences.append(index)\n",
    "new_seq = np.delete(seq,bad_sequences,axis=0)\n",
    "new = new_seq.reshape((new_seq.shape[0]*new_seq.shape[1],new_seq.shape[2]))\n",
    "df = pd.DataFrame(new,columns=['MMSI','# Timestamp','Latitude', 'Longitude' ,'SOG','Heading','DateDiff','Lat_speed','Long_speed','Lat_lag','Long_lag','haversine_distance'])\n",
    "\n",
    "df['d_Lat'] = df['Lat_lag'] - df['Latitude']\n",
    "df['d_Long'] = df['Long_lag'] - df['Longitude']\n",
    "\n",
    "### NORMALIZING VALUES existing scaler\n",
    "import joblib\n",
    "\n",
    "small_df = df[['MMSI','# Timestamp']]\n",
    "df = df.drop(columns=['MMSI','# Timestamp'])\n",
    "features=[i for i in df.columns]\n",
    "\n",
    "scaler = joblib.load('sc.joblib')\n",
    "\n",
    "small_df[features] = scaler.transform(df[features])\n",
    "df = small_df\n",
    "df_numpy = df.to_numpy()\n",
    "seq = df_numpy.reshape((new_seq.shape[0],new_seq.shape[1],df.shape[1]))\n",
    "\n",
    "### DIVIDING INTO FEATURE (X) AND TARGET VARIABLES (y)\n",
    "seq_input_length = 30\n",
    "X_test = seq[:,0:seq_input_length,:]\n",
    "X_test_primary = X_test\n",
    "X_test = X_test[:,:,2:]\n",
    "X_test=X_test.astype('float32')\n",
    "\n",
    "seq_output_length = 20\n",
    "model_names = []\n",
    "predictions = []\n",
    "for model_name in os.listdir('D:\\Python\\master thesis\\master-thesis\\models'):\n",
    "    if '.h5' in model_name:\n",
    "        print(model_name)\n",
    "        model = load_model(f'D:\\Python\\master thesis\\master-thesis\\models\\{model_name}')\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        # print(y_pred_test.shape)\n",
    "        y_pred_test= y_pred_test.reshape(y_pred_test.shape[0],20,2)\n",
    "        y_pred_test = np.concatenate((np.zeros((y_pred_test.shape[0], y_pred_test.shape[1], X_test.shape[2] - y_pred_test.shape[2])),y_pred_test),axis=2)\n",
    "        y_pred_test = scaler.inverse_transform(y_pred_test.reshape(y_pred_test.shape[0]*y_pred_test.shape[1],y_pred_test.shape[2]))[:,-2:]\n",
    "        y_pred_test = y_pred_test.reshape((int(y_pred_test.shape[0]/seq_output_length),seq_output_length,2))\n",
    "        print(y_pred_test.shape)\n",
    "        model_names.append(model_name)\n",
    "        predictions.append(y_pred_test)\n",
    "\n",
    "\n",
    "X_test = scaler.inverse_transform(X_test.reshape(X_test.shape[0]*X_test.shape[1],X_test.shape[2]))\n",
    "X_test = X_test.reshape((int(X_test.shape[0]/seq_input_length),seq_input_length,12))\n",
    "# y_test = diff_to_coord(y_test,X_test)\n",
    "predictions_new = []\n",
    "for y_pred in predictions:\n",
    "    y_pred_test = diff_to_coord(y_pred,X_test)\n",
    "    predictions_new.append(y_pred_test)\n",
    "predictions = predictions_new\n",
    "\n",
    "predictions_new = []\n",
    "for y_pred_test in tqdm(predictions):\n",
    "    last_timestamps = X_test_primary[:, -1, 1]    \n",
    "    y_pred_timestamps = []\n",
    "    for seq_index, last_timestamp in enumerate(last_timestamps):\n",
    "        timestamps = [last_timestamp + np.timedelta64(i + 1, 'm') for i in range(20)]\n",
    "        # print(timestamps)\n",
    "        y_pred_timestamps.append(timestamps)\n",
    "    y_pred_timestamps = np.array(y_pred_timestamps)[..., np.newaxis]\n",
    "    # print(y_pred_timestamps.shape)\n",
    "    y_pred_test_with_timestamps = np.concatenate((y_pred_timestamps,y_pred_test), axis=-1)\n",
    "    adjusted_identifier = X_test_primary[:,:20,0]\n",
    "    adjusted_identifier = adjusted_identifier[..., np.newaxis]\n",
    "    y_pred_test_with_identifier = np.concatenate((adjusted_identifier,y_pred_test_with_timestamps ), axis=-1)\n",
    "    predictions_new.append(y_pred_test_with_identifier)    \n",
    "predictions = predictions_new\n",
    "new_predictions= np.stack(predictions,axis=-1)\n",
    "\n",
    "total_interactions = 0\n",
    "interactions = []\n",
    "for i in tqdm(range(X_test_primary.shape[0])):\n",
    "    for j in range(X_test_primary.shape[0]):\n",
    "        if j > i and X_test_primary[i,0,0] != X_test_primary[j,0,0] and not(X_test_primary[i,-1,1] + np.timedelta64(19,'m') < X_test_primary[j,-1,1] or X_test_primary[j,-1,1] + np.timedelta64(19,'m') < X_test_primary[i,-1,1]):\n",
    "            total_interactions+=1\n",
    "            interactions.append([i,j,1])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize_ellipse(prediction_region,with_points=True,legend=True,label=True,vizualize=True):\n",
    "    \"\"\"\n",
    "    Vizualizes confide ellipse around a bi-variate cluster\n",
    "\n",
    "    Args:\n",
    "        prediction_region : np.array of size (2,x) where x > 1, prediction_region[0] = Latitude, prediction_region[1] = Longitude\n",
    "        with_points : additionally scatter plot with points and mean\n",
    "    \"\"\"\n",
    "\n",
    "    t = np.linspace(0,2.0 * np.pi,1000)\n",
    "    xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "    covariance = np.cov(prediction_region[1,:].astype('float'),prediction_region[0,:].astype('float'))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "    val = np.sqrt(eigenvalues)\n",
    "    center = np.mean([prediction_region[1,:].astype('float'),prediction_region[0,:].astype('float')],axis=1)[:,None]\n",
    "    if vizualize:\n",
    "        if with_points:\n",
    "            plt.scatter(prediction_region[1,:],prediction_region[0,:],label='Predicted points',color='#1f77bd')\n",
    "            plt.scatter(center[0],center[1],label='Mean prediction',color='#ff7f0e')\n",
    "        if label:\n",
    "            plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),label='Predicted trajectory regions',color='#2ca02c')\n",
    "        else:\n",
    "            plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),color='#2ca02c')\n",
    "        # plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),label='95% confidence ellipse',color='#2ca02c')\n",
    "        if legend:\n",
    "            plt.legend(loc='upper right')\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        plt.gca().locator_params(nbins=5)\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "    else:\n",
    "        pass\n",
    "    return covariance,eigenvectors,val,eigenvalues,center\n",
    "\n",
    "def point_intersection(scatter1,scatter2,vizualize=False):\n",
    "    # plt.scatter(scatter1[3,:],scatter1[2,:])\n",
    "    # # plt.scatter(scatter2[3,:],scatter2[2,:])\n",
    "    ## Point intersection\n",
    "    covariance1 = np.cov(scatter1[3,:].astype('float'),scatter1[2,:].astype('float'))\n",
    "    covariance2 = np.cov(scatter2[3,:].astype('float'),scatter2[2,:].astype('float'))\n",
    "    \n",
    "    eigenvalues1, eigenvectors1 = np.linalg.eig(covariance1)\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(covariance2)\n",
    "    val1 = np.sqrt(eigenvalues1)\n",
    "    val2 = np.sqrt(eigenvalues2)\n",
    "    center1 = np.mean([scatter1[3,:].astype('float'),scatter1[2,:].astype('float')],axis=1)[:,None]\n",
    "    center2 = np.mean([scatter2[3,:].astype('float'),scatter2[2,:].astype('float')],axis=1)[:,None]\n",
    "    intersection_points = 0\n",
    "    for point_idx in range(scatter1.shape[1]):\n",
    "        point1 = scatter1[2:4,point_idx]\n",
    "        point1 = np.flip(point1)\n",
    "        point2 = scatter2[2:4,point_idx]\n",
    "        point2 = np.flip(point2)\n",
    "        # plt.scatter(point[1],point[0])\n",
    "        if (point1 - center2.flatten()) @ (np.linalg.inv((5.991)*covariance2)) @ (point1 - center2.flatten()) < 1:\n",
    "            intersection_points += 1 #skaiciuojam ar point in ar out ellipse \n",
    "            plt.scatter(point1[0],point1[1],color='red')\n",
    "        if (point2 - center1.flatten()) @ (np.linalg.inv((5.991)*covariance1)) @ (point2 - center1.flatten()) < 1:\n",
    "            intersection_points += 1 #skaiciuojam ar point in ar out ellipse\n",
    "            plt.scatter(point2[0],point2[1],color='red')\n",
    "    if intersection_points > 0 and vizualize == True:\n",
    "        vizualize_ellipse(scatter1[2:4,:],True,False,False)\n",
    "        vizualize_ellipse(scatter2[2:4,:],True,False,False)\n",
    "    return intersection_points\n",
    "\n",
    "def ellipsoidal_area_intersection(scatter1,scatter2):\n",
    "    covariance1 = np.cov(scatter1[3,:].astype('float'),scatter1[2,:].astype('float'))\n",
    "    covariance2 = np.cov(scatter2[3,:].astype('float'),scatter2[2,:].astype('float'))\n",
    "    eigenvalues1, eigenvectors1 = np.linalg.eig(covariance1)\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(covariance2)\n",
    "    val1 = np.sqrt(eigenvalues1)\n",
    "    val2 = np.sqrt(eigenvalues2)\n",
    "    center1 = np.mean([scatter1[3,:].astype('float'),scatter1[2,:].astype('float')],axis=1)[:,None]\n",
    "    center2 = np.mean([scatter2[3,:].astype('float'),scatter2[2,:].astype('float')],axis=1)[:,None]\n",
    "    ellipse1 = 2.44765*eigenvectors1 @ (val1 * xy).T + center1\n",
    "    ellipse2 = 2.44765*eigenvectors2 @ (val2 * xy).T + center2\n",
    "    polygon1 = Polygon(ellipse1.T)\n",
    "    polygon2 = Polygon(ellipse2.T)\n",
    "    intersection = polygon1.intersection(polygon2)\n",
    "    if not intersection.is_empty:\n",
    "        \n",
    "        intersection_area = intersection.area\n",
    "        # print(f\"The area of intersection is: {intersection_area}\")\n",
    "        # print(f\"Intersection percentage {round((intersection_area*100)/(polygon1.area + polygon2.area - intersection_area),2)}%\")\n",
    "        iou = (intersection_area*100)/(polygon1.area + polygon2.area - intersection_area)\n",
    "        intersection_x,intersection_y = intersection.exterior.xy\n",
    "        plt.fill(intersection_x,intersection_y,alpha=0.4,color='y')\n",
    "        \n",
    "        # inset_position = [0.65, 0.65, 0.25, 0.25]  # [left, bottom, width, height] in figure coordinates\n",
    "        # inset_ax = plt.axes(inset_position)  # Create inset axes\n",
    "        # inset_ax.ticklabel_format(useOffset=False)\n",
    "        # inset_ax.fill(intersection_x,intersection_y,alpha=0.4,color='y')\n",
    "        # inset_ax.set_xlim(12.2139, 12.2142)\n",
    "        # inset_ax.set_ylim(54.5513, 54.5514)\n",
    "        # # inset_ax.set_xticklabels([])\n",
    "        # inset_ax.set_title(\"Zoomed in intersection\", fontsize=10)\n",
    "        # inset_ax.tick_params(labelsize=8)  # Smaller ticks for inset\n",
    "\n",
    "        return intersection.area,iou\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def z_score_bounding_box(vessel_cluster, z_score):\n",
    "    vessel1_long_m,vessel1_lat_m = np.mean([vessel_cluster[3,:],vessel_cluster[2,:]],axis=1)\n",
    "    vessel1_long_std,vessel1_lat_std = np.std(np.array(vessel_cluster[3,:])),np.std(np.array(vessel_cluster[2,:]))\n",
    "    \n",
    "    vessel1_long_lim_min = vessel1_long_m  - vessel1_long_std*z_score\n",
    "    vessel1_long_lim_max = vessel1_long_m  + vessel1_long_std*z_score\n",
    "    vessel1_lat_lim_min = vessel1_lat_m  - vessel1_lat_std*z_score\n",
    "    vessel1_lat_lim_max = vessel1_lat_m  + vessel1_lat_std*z_score\n",
    "    coord1 = [vessel1_long_lim_min,vessel1_lat_lim_min]\n",
    "    coord2 = [vessel1_long_lim_min,vessel1_lat_lim_max]\n",
    "    coord3 = [vessel1_long_lim_max,vessel1_lat_lim_max]\n",
    "    coord4 = [vessel1_long_lim_max,vessel1_lat_lim_min]\n",
    "    square_coord = np.vstack((coord1,coord2,coord3,coord4,coord1)).T\n",
    "    return square_coord\n",
    "\n",
    "def square_intersection_area(square1,square2):\n",
    "    sq1_b_l =np.min(square1,axis=1)\n",
    "    sq1_t_r= np.max(square1,axis=1)\n",
    "    sq2_b_l =np.min(square2,axis=1)\n",
    "    sq2_t_r= np.max(square2,axis=1)\n",
    "    x_l = max(sq1_b_l[0],sq2_b_l[0])\n",
    "    y_b = max(sq1_b_l[1],sq2_b_l[1])\n",
    "    x_r = min(sq1_t_r[0],sq2_t_r[0])\n",
    "    y_t = min(sq1_t_r[1],sq2_t_r[1])\n",
    "    coord1 = [x_l,y_b]\n",
    "    coord2 = [x_l,y_t]\n",
    "    coord3 = [x_r,y_t]\n",
    "    coord4 = [x_r,y_b]\n",
    "    if x_l < x_r and y_b < y_t:\n",
    "        width = x_r - x_l\n",
    "        height = y_t - y_b\n",
    "        area = width * height\n",
    "        sq1_area = (sq1_t_r[0] - sq1_b_l[0]) * (sq1_t_r[1] - sq1_b_l[1])\n",
    "        sq2_area = (sq2_t_r[0] - sq2_b_l[0]) * (sq2_t_r[1] - sq2_b_l[1])\n",
    "        iou = area/(sq1_area+sq2_area-area)\n",
    "        intersect_coords = np.vstack((coord1,coord2,coord3,coord4,coord1)).T\n",
    "        return area,iou,intersect_coords\n",
    "    else:\n",
    "        # print('Squares do not intersect')\n",
    "        return 0,0,[]\n",
    "    \n",
    "def gmm(scatter1,scatter2):\n",
    "    np.random.seed(1)\n",
    "    cluster_1 = scatter1[2:4].T  # Cluster 1 (centered at [-2, -2])\n",
    "    cluster_2 = scatter2[2:4].T    # Cluster 2 (centered at [2, 2])\n",
    "\n",
    "    # # Combine the clusters into one array\n",
    "    data = np.vstack([cluster_1, cluster_2])\n",
    "    dataframe = pd.DataFrame(data, columns=['Latitude', 'Longitude'])\n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=42)\n",
    "    gmm.fit(data)\n",
    "    labels = gmm.predict(data)  # Cluster assignments\n",
    "    labels = np.array([0] * 10 + [1] * 10)\n",
    "    dataframe['Cluster'] = labels\n",
    "    g = sns.JointGrid(data=dataframe, x='Longitude', y='Latitude')\n",
    "    g.ax_joint.ticklabel_format(useOffset=False)\n",
    "\n",
    "    # Add scatter points for each cluster with different colors\n",
    "    colors = ['red', 'blue']\n",
    "    for cluster_id, color in enumerate(colors):\n",
    "        cluster_data = dataframe[dataframe['Cluster'] == cluster_id]\n",
    "        g.ax_joint.scatter(\n",
    "            cluster_data['Longitude'],\n",
    "            cluster_data['Latitude'],\n",
    "            label=f'Cluster {cluster_id + 1}',\n",
    "            color=color,\n",
    "            s=20,\n",
    "            alpha=1\n",
    "    )\n",
    "\n",
    "    kde1_long = gaussian_kde(np.array(cluster_1[:,1],dtype='float'))\n",
    "    kde2_long = gaussian_kde(np.array(cluster_2[:,1],dtype='float'))\n",
    "    kde1_lat = gaussian_kde(np.array(cluster_1[:,0],dtype='float'))\n",
    "    kde2_lat = gaussian_kde(np.array(cluster_2[:,0],dtype='float'))\n",
    "\n",
    "    x_long = np.linspace(min(min(cluster_1[:,1]), min(cluster_2[:,1]))-0.001, max(max(cluster_1[:,1]), max(cluster_2[:,1]))+0.001, 1000)\n",
    "    x_lat = np.linspace(min(min(cluster_1[:,0]), min(cluster_2[:,0]))-0.001, max(max(cluster_1[:,0]), max(cluster_2[:,0]))+0.001, 1000)\n",
    "\n",
    "\n",
    "\n",
    "    kde1_values_long = kde1_long(x_long)\n",
    "    kde2_values_long = kde2_long(x_long)\n",
    "\n",
    "    kde1_values_lat = kde1_lat(x_lat)\n",
    "    kde2_values_lat = kde2_lat(x_lat)\n",
    "\n",
    "    g.ax_marg_x.plot(x_long, kde1_values_long, label='Cluster Data 1', lw=2,color=colors[0])\n",
    "    g.ax_marg_x.plot(x_long, kde2_values_long, label='Cluster Data 2', lw=2,color=colors[1])\n",
    "    g.ax_marg_x.fill_between(x_long, kde1_values_long, alpha=0.2, label='Intersection',color='red')\n",
    "    g.ax_marg_x.fill_between(x_long, kde2_values_long, alpha=0.2, label='Intersection',color='blue')\n",
    "    g.ax_marg_x.fill_between(x_long, np.minimum(kde1_values_long, kde2_values_long), alpha=0.5, label='Intersection',color='yellow')\n",
    "\n",
    "    g.ax_marg_y.plot(kde1_values_lat,x_lat, label='Cluster Data 1', lw=2,color=colors[0])\n",
    "    g.ax_marg_y.plot(kde2_values_lat,x_lat, label='Cluster Data 2', lw=2,color=colors[1])\n",
    "    g.ax_marg_y.fill_betweenx(x_lat,kde1_values_lat, alpha=0.2, label='Intersection',color='red')\n",
    "    g.ax_marg_y.fill_betweenx(x_lat,kde2_values_lat, alpha=0.2, label='Intersection',color='blue')\n",
    "    g.ax_marg_y.fill_betweenx(x_lat,np.minimum(kde1_values_lat, kde2_values_lat), alpha=0.5, label='Intersection',color='yellow')\n",
    "    \n",
    "    intersection_area_long = np.trapz(np.minimum(kde1_values_long, kde2_values_long), x_long)\n",
    "    intersection_area_lat = np.trapz(np.minimum(kde1_values_lat, kde2_values_lat), x_long)\n",
    "    print(f\"Longitude intersection area {intersection_area_long}\")\n",
    "    print(f\"Latitude intersection area {intersection_area_lat}\")\n",
    "    print(f\"Intersection area multiplied {intersection_area_long*intersection_area_lat}\")\n",
    "    print('------')\n",
    "    plt.show()\n",
    "    return intersection_area_long*intersection_area_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELLIPSOIDAL POINT INTERSECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.ticklabel_format(useOffset=False)\n",
    "t = np.linspace(0,2.0 * np.pi,1000)\n",
    "xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "for interaction in tqdm(interactions):\n",
    "    plt.plot(X_test[interaction[0],:,1],X_test[interaction[0],:,0]) #first ship predictor\n",
    "    plt.plot(X_test[interaction[1],:,1],X_test[interaction[1],:,0]) #second ship predictor\n",
    "    \n",
    "    intersection = np.intersect1d(y_pred_test_with_identifier[interaction[0],:,1],y_pred_test_with_identifier[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        plt.gca().locator_params(nbins=5)\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        covariance1,eigenvectors1,val1,eigenvalues1,center1 = vizualize_ellipse(scatter1[2:4,:],False,False,False,False)\n",
    "        covariance2,eigenvectors2,val2,eigenvalues2,center2 = vizualize_ellipse(scatter2[2:4,:],False,False,False,False)\n",
    "        plt.plot(*(2.44765*eigenvectors1 @ (val1 * xy).T + center1),color=palette[i])\n",
    "        plt.plot(*(2.44765*eigenvectors2 @ (val2 * xy).T + center2),color=palette[i])\n",
    "        intersection_points = point_intersection(scatter1,scatter2,False)\n",
    "        print(intersection_points)\n",
    "        # plt.show()\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "plt.plot(original_data[original_data['MMSI']== 232018267.0][:147][-3:]['Longitude'],original_data[original_data['MMSI']== 232018267.0][:147][-3:]['Latitude'],color='red',alpha=0.5)\n",
    "plt.plot(original_data[original_data['MMSI'] == 219021240.0][-3:]['Longitude'],original_data[original_data['MMSI'] == 219021240.0][-3:]['Latitude'],color='orange',alpha=0.5)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELLIPSOIDAL AREA INTERSECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ticklabel_format(useOffset=False)\n",
    "t = np.linspace(0,2.0 * np.pi,1000)\n",
    "xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "for interaction in tqdm(interactions):\n",
    "    # plt.plot(X_test[interaction[0],:,1],X_test[interaction[0],:,0]) #first ship predictor\n",
    "    # plt.plot(X_test[interaction[1],:,1],X_test[interaction[1],:,0]) #second ship predictor\n",
    "    \n",
    "    intersection = np.intersect1d(y_pred_test_with_identifier[interaction[0],:,1],y_pred_test_with_identifier[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        if i == 3:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        covariance1,eigenvectors1,val1,eigenvalues1,center1 = vizualize_ellipse(scatter1[2:4,:],False,False,False,False)\n",
    "        covariance2,eigenvectors2,val2,eigenvalues2,center2 = vizualize_ellipse(scatter2[2:4,:],False,False,False,False)\n",
    "        plt.plot(*(2.44765*eigenvectors1 @ (val1 * xy).T + center1),color=palette[i])\n",
    "        plt.plot(*(2.44765*eigenvectors2 @ (val2 * xy).T + center2),color=palette[i])\n",
    "        # intersection_points = point_intersection(scatter1,scatter2,False)\n",
    "        area,iou = ellipsoidal_area_intersection(scatter1,scatter2)\n",
    "        print(area,iou)\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.xlim([14.2428,14.2431])\n",
    "        plt.ylim([55.22235,55.2226])\n",
    "        plt.show()\n",
    "        # if area > 0:\n",
    "        #     print(interaction)\n",
    "        #     print(scatter1[:,0])\n",
    "        #     print(scatter2[:,0])\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-SCORE INTERSECTION AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z-score intersection area\n",
    "\n",
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    plt.plot(X_test[interaction[0],:,1],X_test[interaction[0],:,0]) #first ship predictor\n",
    "    plt.plot(X_test[interaction[1],:,1],X_test[interaction[1],:,0]) #second ship predictor\n",
    "    \n",
    "    intersection = np.intersect1d(y_pred_test_with_identifier[interaction[0],:,1],y_pred_test_with_identifier[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        square_coord1 = z_score_bounding_box(scatter1,3)\n",
    "        square_coord2 = z_score_bounding_box(scatter2,3)\n",
    "        area, iou,intersect_coords= square_intersection_area(square_coord1,square_coord2)\n",
    "        # plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red')\n",
    "        # plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange')\n",
    "        # print(area,iou)\n",
    "        plt.plot(square_coord1[0],square_coord1[1],color=palette[i])\n",
    "        plt.plot(square_coord2[0],square_coord2[1],color=palette[i])\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        \n",
    "        if area > 0:\n",
    "            plt.fill(intersect_coords[0],intersect_coords[1],color = 'y',alpha= 0.3)\n",
    "        print(iou)\n",
    "plt.plot(original_data[original_data['MMSI']== 232018267.0][:147][-10:]['Longitude'],original_data[original_data['MMSI']== 232018267.0][:147][-10:]['Latitude'],color='red',alpha=0.5)\n",
    "plt.plot(original_data[original_data['MMSI'] == 219021240.0][-10:]['Longitude'],original_data[original_data['MMSI'] == 219021240.0][-10:]['Latitude'],color='orange',alpha=0.5)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    intersection = np.intersect1d(y_pred_test_with_identifier[interaction[0],:,1],y_pred_test_with_identifier[interaction[1],:,1])\n",
    "    # if interaction[2] == 1:\n",
    "    highest_per_interaction = 0\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        \n",
    "        # plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        # plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        score = gmm(scatter1,scatter2)\n",
    "        # plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red')\n",
    "        # plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange')\n",
    "        if score > highest_per_interaction:\n",
    "            highest_per_interaction = score\n",
    "    print(highest_per_interaction)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SILHOUETTE VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Silhouette\n",
    "silhouette_interactions = []\n",
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    intersection = np.intersect1d(y_pred_test_with_identifier[interaction[0],:,1],y_pred_test_with_identifier[interaction[1],:,1])\n",
    "    # if interaction[0] == 2351 and interaction[1] == 8929:\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     continue\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    lowest_per_interaction = 1\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        cluster1_points = scatter1[2:4,:].T\n",
    "        cluster2_points = scatter2[2:4,:].T\n",
    "        combined_data = np.vstack([cluster1_points, cluster2_points])\n",
    "        labels = np.array([0] * cluster1_points.shape[0] + [1] * cluster2_points.shape[0])\n",
    "        silhouette_avg = silhouette_score(combined_data, labels)\n",
    "        # print(f\"Silhoutte power score: {(1-silhouette_avg)**(1./20)}\")\n",
    "        # print(f\"Silhouette Value: {silhouette_avg}\")\n",
    "        if silhouette_avg < lowest_per_interaction:\n",
    "            lowest_per_interaction = silhouette_avg\n",
    "        # print(1-silhouette_avg)\n",
    "        print(n_root(1 - silhouette_avg,10))\n",
    "        \n",
    "        # print(f\"Silhoutte logistic score: {(1-(1./(1+math.e**(-12*(silhouette_avg-0.5)))))}\")\n",
    "\n",
    "        # plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        # plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        # plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red')\n",
    "        # plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange')\n",
    "    silhouette_interactions.append([1-lowest_per_interaction,interaction[2]])\n",
    "    \n",
    "\n",
    "    # print(highest_per_interaction)\n",
    "# gmm_interactions = np.array(gmm_interactions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_root(x,n):\n",
    "    return x**(1./n)    \n",
    "def n_logistic(x,n):\n",
    "    return (1-(1./(1+math.e**(n*(x-0.5)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
