{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS AND GLOBAL VARIABLES\n",
    "\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import AntPath, MousePosition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from geopy.point import Point\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import random\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "from pyproj import Geod\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from folium.plugins import HeatMap\n",
    "MIN_LAT = 54.00\n",
    "MAX_LAT = 56.00\n",
    "MIN_LONG = 12.00\n",
    "MAX_LONG = 15.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Python\\master thesis\\data\\cleaned_aisdk-2024-09-14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n",
    "\n",
    "def draw_ship(mmsi,df):\n",
    "    df_mmsi = df[df['MMSI'] == mmsi]\n",
    "    path = []\n",
    "    for row in df_mmsi.iterrows():\n",
    "        lat_long = (row[1]['Latitude'],row[1]['Longitude'])\n",
    "        path.append(lat_long)\n",
    "    map_object = folium.Map(location=[np.average(df_mmsi['Latitude']),np.average(df_mmsi['Longitude'])],zoom_start=8)\n",
    "    AntPath(path,delay=400,weight=3,dash_array=[30,15]).add_to(map_object)\n",
    "    folium.CircleMarker(location=path[0],radius=10,fill=True,fill_opacity=0.6,popup=\"start\" + str(mmsi)).add_to(map_object)\n",
    "    folium.CircleMarker(location=path[-1],radius=10,fill=True,fill_opacity=0.6,popup=\"end\" + str(mmsi)).add_to(map_object)\n",
    "    # for a,enumer in path:\n",
    "    #     folium.CircleMarker(location=a,radius=1,fill=True,fill_opacity=0.9).add_to(map_object)\n",
    "    MousePosition().add_to(map_object)\n",
    "    map_object.save('map.html')\n",
    "\n",
    "def draw_bounding_box(lats, longs):\n",
    "    map_object = folium.Map(location=[np.average(lats),np.average(longs)],zoom_start=8)\n",
    "    path = [(lats[0],longs[0]),(lats[0],longs[1]),(lats[1],longs[1]),(lats[1],longs[0]),(lats[0],longs[0])]\n",
    "    AntPath(path,delay=1000000,weight=3,color='red',dash_array=[0,0]).add_to(map_object)\n",
    "    MousePosition().add_to(map_object)\n",
    "    map_object.save('map.html')\n",
    "\n",
    "# def haversine_distance(point1, point2):\n",
    "#     return great_circle(Point(point1), Point(point2)).kilometers\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "\n",
    "def draw_ships(number_of_ships,df,map_object=None):\n",
    "    all_mmsis = df['MMSI'].unique()\n",
    "    selected_mmsis = []\n",
    "    if map_object is None:\n",
    "        map_object = folium.Map(location=[54.8292,12.9694],zoom_start=8)\n",
    "    while (len(selected_mmsis) < number_of_ships) and (len(selected_mmsis) < len(all_mmsis)):\n",
    "        mmsi = random.choice(all_mmsis)\n",
    "        if mmsi not in selected_mmsis:\n",
    "            selected_mmsis.append(mmsi)\n",
    "    for i in tqdm(selected_mmsis):\n",
    "        df_mmsi = df[df['MMSI'] == i]\n",
    "        path = []\n",
    "        color = \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "        for row in df_mmsi.iterrows():\n",
    "            lat_long = (row[1]['Latitude'],row[1]['Longitude'])\n",
    "            path.append(lat_long)\n",
    "        AntPath(path,delay=1,weight=20,color='blue',dash_array=[1000,1],paused=True).add_to(map_object)\n",
    "        # folium.CircleMarker(location=path[0],radius=10,fill=True,fill_opacity=0.6,popup=\"start\" + str(i)).add_to(map_object)\n",
    "        # folium.CircleMarker(location=path[-1],radius=10,fill=True,fill_opacity=0.6,popup=\"end\" + str(i)).add_to(map_object)\n",
    "    MousePosition().add_to(map_object)\n",
    "    map_object.save('map.html')\n",
    "\n",
    "def static_value_clean(df):\n",
    "    for i in ['Ship type','Width','Length']:\n",
    "        most_frequent_type = (df\n",
    "                            .groupby('MMSI')[i]\n",
    "                            .agg(lambda x: x.value_counts(dropna=False).idxmax())\n",
    "                            .reset_index()\n",
    "                            .rename(columns={i: 'most_frequent_type'}))\n",
    "\n",
    "        df = df.merge(most_frequent_type,on='MMSI',how='left')\n",
    "        df[i] = df.apply(lambda row: row['most_frequent_type'] if row[i] != row['most_frequent_type'] else row[i], axis=1)\n",
    "        df.drop('most_frequent_type', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MASS CLEANING\n",
    "files_list = [i for i in os.listdir('D:\\Python\\master thesis\\master-thesis')]\n",
    "path = 'D:\\Python\\master thesis\\data'\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    if 'cleaned' not in file and f'cleaned_{file}' not in files_list:\n",
    "        print(file)\n",
    "        file_path = os.path.join(path,file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[(df['Latitude']<MAX_LAT)&(df['Latitude']>MIN_LAT)&(df['Longitude']<MAX_LONG)&(df['Longitude']>MIN_LONG)] \n",
    "        df = df[df['Ship type'] == 'Cargo']\n",
    "        df['# Timestamp'] = pd.to_datetime(df['# Timestamp']) \n",
    "        df = df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "        df = df.drop_duplicates(subset=['# Timestamp','MMSI'],keep='first')\n",
    "        df = df.drop(columns=['Type of position fixing device','Data source type','IMO','Callsign','ROT','Cargo type','Destination','Name','A','B','C','D'], errors='ignore')\n",
    "        df.to_csv(f'D:\\Python\\master thesis\\data\\cleaned_{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joining all files\n",
    "try:\n",
    "    del df\n",
    "    del final_path\n",
    "except:\n",
    "    pass\n",
    "path = 'D:\\Python\\master thesis\\data'\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    if 'cleaned' in file:\n",
    "        file_path = os.path.join(path,file)\n",
    "        df = pd.read_csv(os.path.join(path,file))\n",
    "        if 'final_path' in locals():\n",
    "            final_path = pd.concat([final_path,df])\n",
    "        else:\n",
    "            final_path = df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path.to_csv('joined_cleaned_aisdk-2024-09-14 - 2024-10-14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ DATA\n",
    "df = pd.read_csv(r'D:\\Python\\master thesis\\data\\joined_cleaned_aisdk-2024-09-14 - 2024-10-14.csv')\n",
    "# df = pd.read_csv(r'D:\\Python\\master thesis\\data\\aisdk-2024-10-14.csv')\n",
    "# df = pd.read_csv(r\"C:\\Users\\Kasparas\\Desktop\\master thesis\\data\\first_mil_rows.csv\")\n",
    "# df = pd.read_csv(r\"C:\\Users\\Kasparas\\Desktop\\master thesis\\data\\downsample_dataset.csv\")\n",
    "# df = pd.read_csv(r\"C:\\Users\\Kasparas\\Desktop\\master thesis\\data\\final_dataset.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0','Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DROPING DUPLICATES (ONLY WHERE DUPLICATES ARE TIMESTAMP AND MMSI) KEEPING FIRST RECORD\n",
    "\n",
    "df = df.drop_duplicates(subset=['# Timestamp','MMSI'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVING IRRELEVANT COLUMNS\n",
    "###   Type of position fixing device - data related to transmission and not to vessel traffic\n",
    "###   Data source type - data related to transmission and not to vessel traffic\n",
    "###   IMO - unique identifier for vessel, MMSI does the job\n",
    "###   Callsign - unique identifier for vessel, MMSI does the job\n",
    "###   ROT - too many empty values for the columns to be considered useful\n",
    "###   Name - too many empty values for the columns to be considered useful\n",
    "###   Cargo type - too many empty values for the columns to be considered useful\n",
    "###   Destination - too many empty values for the columns to be considered useful\n",
    "\n",
    "df = df.drop(columns=['Type of position fixing device','Data source type','IMO','Callsign','ROT','Cargo type','Destination','Name','A','B','C','D'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resampling\n",
    "\n",
    "mmsis = df['MMSI'].unique()\n",
    "mmsis_df = pd.DataFrame([])\n",
    "for mmsi in tqdm(mmsis):\n",
    "    mmsi_df= df[df['MMSI'] == mmsi]\n",
    "    mmsi_df = mmsi_df.set_index('# Timestamp')\n",
    "    mmsi_df = mmsi_df.resample('60s').nearest(limit=1).dropna(how='all')\n",
    "    mmsi_df = mmsi_df.reset_index()\n",
    "    mmsi_df = mmsi_df.drop_duplicates(subset=['# Timestamp','MMSI'],keep='first')\n",
    "    mmsi_df = mmsi_df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "    mmsis_df = pd.concat([mmsis_df,mmsi_df])\n",
    "mmsis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsis_df.to_csv('downsampled_joined_cleaned_aisdk_2024-09-14 - 2024-10-14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATEDIFF BETWEEN CURRENT AND PREVIOUS TIMESTAMP\n",
    "\n",
    "df['DateDiff'] =  (df['# Timestamp'] - df.groupby('MMSI')['# Timestamp'].shift(1)).dt.total_seconds().fillna(0).astype(int) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LATITUDE/LONGITUDE SPEED AND LAGS\n",
    "\n",
    "df['Lat_speed'] =  ((df['Latitude'] - df.groupby('MMSI')['Latitude'].shift(1)) / (df['DateDiff']/60)).fillna(0)\n",
    "df['Long_speed'] =  ((df['Longitude'] - df.groupby('MMSI')['Longitude'].shift(1)) / (df['DateDiff']/60)).fillna(0)\n",
    "df['Lat_lag'] = df.groupby('MMSI')['Latitude'].shift(1)\n",
    "df['Long_lag'] = df.groupby('MMSI')['Longitude'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HAVERSINE DISTANCE COLUMN\n",
    "\n",
    "haversine_distance = []\n",
    "for index,row in df.iterrows():\n",
    "    hav = haversine(row['Longitude'],row['Latitude'],row['Long_lag'],row['Lat_lag'])\n",
    "    haversine_distance.append(hav)\n",
    "df['haversine_distance'] = haversine_distance\n",
    "df['haversine_distance'] = df['haversine_distance']*1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RELEVANT COLUMNS FILTER\n",
    "\n",
    "df = df[['MMSI', '# Timestamp', 'Latitude', 'Longitude', 'SOG', 'Heading', 'DateDiff', 'Lat_speed','Long_speed','Lat_lag','Long_lag','haversine_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
