{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import folium\n",
    "from folium.plugins import AntPath, MousePosition\n",
    "from sklearn.utils import shuffle, resample\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, RepeatVector, GRU, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET LOAD\n",
    "\n",
    "df = pd.read_csv(r\"D:\\Python\\master thesis\\data\\final_dataset.csv\")\n",
    "# df = pd.read_csv(r\"D:\\Python\\master thesis\\collision data\\final_dataset_collision.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['# Timestamp'] = pd.to_datetime(df['# Timestamp'])\n",
    "df = df.sort_values(by=['MMSI', '# Timestamp'])\n",
    "# # # Display the first few rows of the dataset to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Differences of Lat and Long conversion to coordinates\n",
    "def diff_to_coord(y,X):\n",
    "    a = np.zeros_like(y)\n",
    "    for j in tqdm(range(a.shape[0])):\n",
    "        for i in range(a.shape[1]):\n",
    "            if i == 0:\n",
    "                a[j,i,0] = X[j,-1,0] - y[j,i,0]\n",
    "                a[j,i,1] = X[j,-1,1] - y[j,i,1]\n",
    "            else:\n",
    "                a[j,i,0] = a[j,i-1,0] - y[j,i,0]\n",
    "                a[j,i,1] = a[j,i-1,1] - y[j,i,1]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequencing\n",
    "seq_input_length = 30\n",
    "seq_output_length = 20\n",
    "seq_length = seq_input_length+seq_output_length\n",
    "window_size = seq_length // 2\n",
    "\n",
    "seq = []\n",
    "for i in tqdm(range(0, len(df) - seq_length + 1, window_size)):\n",
    "    temp = df[i: i + seq_length].values\n",
    "    # check if all sequences hold only one MMSI (first == last)\n",
    "    if(temp[0,0] == temp[-1,0]):\n",
    "        seq.append(temp)\n",
    "seq = np.dstack(seq)\n",
    "seq = np.rollaxis(seq,-1)\n",
    "# seq = shuffle(seq,random_state=42)\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removal of bad sequences e.g. SOG = 0, irregular timesteps, calculated speed = 0, NaNs, illogical speed\n",
    "bad_sequences = []\n",
    "for index,i in tqdm(enumerate(seq)):\n",
    "    # print(index)\n",
    "    if 0 in i[:,4] or (i[:,6] > 2).sum() > 0 or (i[:,6] < 1).sum() > 0 or 0 in (np.append(np.atleast_2d(i[:,7:9].sum(axis=1)).T,i[:,7:8],axis=1)).sum(axis=1) or np.isnan((i[:,2:].astype(np.float32))).sum() > 0 or (i[:,11] <= 0).sum() > 0 or (i[:,11] > 771).sum() > 0:\n",
    "        bad_sequences.append(index)\n",
    "new_seq = np.delete(seq,bad_sequences,axis=0)\n",
    "new = new_seq.reshape((new_seq.shape[0]*new_seq.shape[1],new_seq.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new,columns=['MMSI','# Timestamp','Latitude', 'Longitude' ,'SOG','Heading','DateDiff','Lat_speed','Long_speed','Lat_lag','Long_lag','haversine_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renewed deltas\n",
    "df['d_Lat'] =  df['Lat_lag'] - df['Latitude']\n",
    "df['d_Long'] = df['Long_lag'] - df['Longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORMALIZING VALUES\n",
    "### if scaler file exists skip this part\n",
    "small_df = df[['MMSI','# Timestamp']]\n",
    "df = df.drop(columns=['MMSI','# Timestamp'])\n",
    "features=[i for i in df.columns]\n",
    "scaler = MinMaxScaler()\n",
    " \n",
    "small_df[features] = scaler.fit_transform(df[features])\n",
    "df = small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scaler file\n",
    "import joblib\n",
    "joblib.dump(scaler, 'sc.joblib') \n",
    "scaler = joblib.load('sc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numpy = df.to_numpy()\n",
    "seq = df_numpy.reshape((new_seq.shape[0],new_seq.shape[1],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividing inot predictor (X) and target variables (y)\n",
    "X = seq[:,0:seq_input_length,:]\n",
    "y = seq[:,seq_input_length:seq_length,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLITTING DATA INTO TRAIN,TEST,VALIDATION (70%,15%,15%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.176,random_state=1)   # 70 : 15 : 15\n",
    "\n",
    "\n",
    "X_train_primary = X_train\n",
    "X_test_primary = X_test\n",
    "X_val_primary = X_val\n",
    "y_train_primary = y_train\n",
    "y_test_primary = y_test\n",
    "y_val_primary = y_val\n",
    "\n",
    "\n",
    "X_train = X_train[:,:,2:]\n",
    "X_test = X_test[:,:,2:]\n",
    "X_val = X_val[:,:,2:]\n",
    "\n",
    "# y_train = y_train[:,:,2:4] # drop all features except lat and long\n",
    "# y_val = y_val[:,:,2:4] # drop all features except lat and long\n",
    "# y_test = y_test[:,:,2:4] # drop all features except lat and long\n",
    "\n",
    "y_train = y_train[:,:,-2:] # drop all features except lat and long\n",
    "y_val = y_val[:,:,-2:] # drop all features except lat and long\n",
    "y_test = y_test[:,:,-2:] # drop all features except lat and long\n",
    "\n",
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_val=X_val.astype('float32')\n",
    "y_train=y_train.astype('float32')\n",
    "y_test=y_test.astype('float32')\n",
    "y_val=y_val.astype('float32')\n",
    "\n",
    "y_train_flat = np.copy(y_train)\n",
    "y_val_flat = np.copy(y_val)\n",
    "y_test_flat = np.copy(y_test)\n",
    "y_train_flat = y_train_flat.reshape(y_train_flat.shape[0], y_train_flat.shape[1]*y_train_flat.shape[2])\n",
    "y_val_flat = y_val_flat.reshape(y_val_flat.shape[0], y_val_flat.shape[1]*y_val_flat.shape[2])\n",
    "y_test_flat = y_test_flat.reshape(y_test_flat.shape[0], y_test_flat.shape[1]*y_test_flat.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mock colissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data prep before mock collisions\n",
    "\n",
    "y_test_copy = np.concatenate((np.zeros((y_test.shape[0], y_test.shape[1], X_test.shape[2] - y_test.shape[2])),y_test),axis=2)\n",
    "y_test_copy = scaler.inverse_transform(y_test_copy.reshape(y_test_copy.shape[0]*y_test_copy.shape[1],y_test_copy.shape[2]))[:,-2:]\n",
    "y_test_copy = y_test_copy.reshape((int(y_test_copy.shape[0]/seq_output_length),seq_output_length,2))\n",
    "\n",
    "X_test = scaler.inverse_transform(X_test.reshape(X_test.shape[0]*X_test.shape[1],X_test.shape[2]))\n",
    "X_test = X_test.reshape((int(X_test.shape[0]/seq_input_length),seq_input_length,X_train.shape[2]))\n",
    "y_test_copy = diff_to_coord(y_test_copy,X_test)\n",
    "\n",
    "y_test_copy = np.concatenate((y_test_primary[:,:,:2],y_test_copy),axis=2)\n",
    "X_test = np.concatenate((X_test_primary[:,:,:2],X_test),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mockup_generator(X_test,y_test,random_ship=True,ship_index1=None,ship_index2=None,timestamp_index1=None,timestamp_index2=None):\n",
    "    \"\"\"\n",
    "    Returns: \n",
    "        random_index- index of first sequence\n",
    "        ship_index - index of second sequence\n",
    "        mmsi - mmsi of ship of first sequence\n",
    "        y_test[ship_index,0,0] - mmsi of ship of first sequence\n",
    "        new_traj_X - changed first sequence predictor variable to imitate collision\n",
    "        new_traj_y - changed first sequence target variable to imitate collision\n",
    "        timestamp_index - timestamp index of first sequence\n",
    "        time_index - timestamp index of second sequence\n",
    "    \"\"\"\n",
    "    if random_ship:\n",
    "        random_index= random.randint(0,X_test.shape[0])\n",
    "        timestamp_index=random.randint(y_test.shape[2]//4,y_test.shape[2]//4*3)\n",
    "        timestamp=y_test[random_index,timestamp_index,1]\n",
    "        mmsi=y_test[random_index,0,0]\n",
    "        index_list = []\n",
    "        for i in range(y_test.shape[0]):\n",
    "            if timestamp in y_test[i,:,1] and mmsi != y_test[i,0,0]:\n",
    "                index_list.append(i)\n",
    "        if len(index_list) == 0:\n",
    "            mockup_generator(X_test,y_test)\n",
    "        else:\n",
    "            ship_index = random.choice(index_list)\n",
    "            time_index= np.where(y_test[ship_index,:,1]==timestamp)[0][0]\n",
    "            differences = y_test[random_index,timestamp_index,2:4] - y_test[ship_index,time_index,2:4]\n",
    "            colission_path_X = X_test[random_index,:,2:4] - differences\n",
    "            colission_path_y = y_test[random_index,:,2:4] - differences\n",
    "            \n",
    "            plt.plot(X_test[random_index,:,3],X_test[random_index,:,2])\n",
    "            plt.plot(y_test[random_index,:,3],y_test[random_index,:,2])\n",
    "            plt.plot(X_test[ship_index,:,3],X_test[ship_index,:,2],label=f'start_path {y_test[ship_index,0,0]}',)\n",
    "            plt.plot(y_test[ship_index,:,3],y_test[ship_index,:,2],label=f'end_path {y_test[ship_index,0,0]}')\n",
    "            plt.plot(colission_path_X[:,1],colission_path_X[:,0],label=f'start_colission_path {y_test[random_index,0,0]}')\n",
    "            plt.plot(colission_path_y[:,1],colission_path_y[:,0],label=f'end_colission_path {y_test[random_index,0,0]}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(X_test[ship_index,:,3],X_test[ship_index,:,2],label=f'start_path {y_test[ship_index,0,0]}',)\n",
    "            plt.plot(y_test[ship_index,:,3],y_test[ship_index,:,2],label=f'end_path {y_test[ship_index,0,0]}')\n",
    "            plt.plot(colission_path_X[:,1],colission_path_X[:,0],label=f'start_colission_path {y_test[random_index,0,0]}')\n",
    "            plt.plot(colission_path_y[:,1],colission_path_y[:,0],label=f'end_colission_path {y_test[random_index,0,0]}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            # print(X_test.shape)\n",
    "            # print(colission_path_X.shape)\n",
    "            # print(X_test[random_index,:,:])\n",
    "            # print(colission_path_X)\n",
    "\n",
    "            X_to_change = X_test[random_index,:,:].copy()\n",
    "            X_to_change[:,2:4] = colission_path_X\n",
    "            X_to_change[:,9:11] = X_to_change[:,2:4] + X_to_change[:,12:14]\n",
    "            y_to_change = y_test[random_index,:,:].copy()\n",
    "            y_to_change[:,2:4] = colission_path_y\n",
    "            new_traj_X =  X_to_change\n",
    "            new_traj_y = y_to_change\n",
    "            return random_index, ship_index ,mmsi ,y_test[ship_index,0,0],new_traj_X, new_traj_y,timestamp_index,time_index\n",
    "    elif not random_ship:\n",
    "        differences = y_test[ship_index1,timestamp_index1,2:4] - y_test[ship_index2,timestamp_index2,2:4]\n",
    "        colission_path_X = X_test[ship_index1,:,2:4] - differences\n",
    "        colission_path_y = y_test[ship_index1,:,2:4] - differences\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax1.set_title(f\"Original trajectories for vessels:\\n$MMSI_1$ = {round(y_test[ship_index1,0,0])}\\n$MMSI_2$ = {round(y_test[ship_index2,0,0])}\")\n",
    "        ax1.plot(X_test[ship_index1,:,3],X_test[ship_index1,:,2],label=f'Original predictor path for vessel MMSI = {y_test[ship_index1,0,0]}',color='#001219')\n",
    "        ax1.plot(y_test[ship_index1,:,3],y_test[ship_index1,:,2],label=f'Original target path for vessel MMSI = {y_test[ship_index1,0,0]}',color='#0a9396')\n",
    "        ax1.plot(X_test[ship_index2,:,3],X_test[ship_index2,:,2],label=f'Original predictor path for vessel MMSI = {y_test[ship_index2,0,0]}',color='#9b2226')\n",
    "        ax1.plot(y_test[ship_index2,:,3],y_test[ship_index2,:,2],label=f'Original target path for vessel MMSI = {y_test[ship_index2,0,0]}',color='#ee9b00')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        # plt.plot(colission_path_X[:,1],colission_path_X[:,0],label=f'Artificial predictor path for vessel MMSI = {y_test[ship_index1,0,0]}')\n",
    "        # plt.plot(colission_path_y[:,1],colission_path_y[:,0],label=f'Artificial target path for vessel MMSI = {y_test[ship_index1,0,0]}')\n",
    "        # plt.legend(fontsize='x-small')\n",
    "        # plt.show()\n",
    "        ax2.set_title(f\"Mock collision trajectories for vessels:\\n$MMSI_1$ = {round(y_test[ship_index1,0,0])}\\n$MMSI_2$ = {round(y_test[ship_index2,0,0])}\")\n",
    "        # plt.plot(X_test[ship_index1,:,3],X_test[ship_index1,:,2],label=f'Original predictor path for vessel MMSI = {y_test[ship_index1,0,0]}')\n",
    "        # plt.plot(y_test[ship_index1,:,3],y_test[ship_index1,:,2],label=f'Original target path for vessel MMSI = {y_test[ship_index1,0,0]}')\n",
    "        ax2.plot(X_test[ship_index2,:,3],X_test[ship_index2,:,2],label=f'Original predictor path for vessel MMSI = {y_test[ship_index2,0,0]}',color='#9b2226')\n",
    "        ax2.plot(y_test[ship_index2,:,3],y_test[ship_index2,:,2],label=f'Original target path for vessel MMSI = {y_test[ship_index2,0,0]}',color='#ee9b00')\n",
    "        ax2.plot(colission_path_X[:,1],colission_path_X[:,0],label=f'Artificial predictor path for vessel MMSI = {y_test[ship_index1,0,0]}',color='#001219')\n",
    "        ax2.plot(colission_path_y[:,1],colission_path_y[:,0],label=f'Artificial target path for vessel MMSI = {y_test[ship_index1,0,0]}',color='#0a9396')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        # plt.legend(fontsize='x-small')\n",
    "        plt.locator_params(axis='both', nbins=4) \n",
    "        plt.show()\n",
    "        X_to_change = X_test[ship_index1,:,:].copy()\n",
    "        X_to_change[:,2:4] = colission_path_X\n",
    "        X_to_change[:,9:11] = X_to_change[:,2:4] + X_to_change[:,12:14]\n",
    "        y_to_change = y_test[ship_index1,:,:].copy()\n",
    "        y_to_change[:,2:4] = colission_path_y\n",
    "        new_traj_X =  X_to_change\n",
    "        new_traj_y = y_to_change\n",
    "        return ship_index1, ship_index2 ,y_test[ship_index1,0,0] ,y_test[ship_index2,0,0],new_traj_X, new_traj_y,timestamp_index1,timestamp_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  RANDOM COLLISIONS\n",
    "### Skip this if collisions are mock collisions are already chosen\n",
    "\n",
    "X_changes = []\n",
    "y_changes = []\n",
    "mmsis = []\n",
    "first_indexes = []\n",
    "second_indexes = []\n",
    "all_indexes = []\n",
    "time_indexes_1 = []\n",
    "time_indexes_2 = []\n",
    "while len(X_changes)<10:\n",
    "    first_idx,second_idx,first_mmsi,second_mmsi,new_traj_X,new_traj_y,first_timestamp_index,second_timestamp_index = mockup_generator(X_test,y_test_copy)\n",
    "    ok = 'y'\n",
    "    ok = input('y or n?')\n",
    "    if first_idx in all_indexes or second_idx in all_indexes or ok != 'y':\n",
    "        continue\n",
    "    X_changes.append(new_traj_X)\n",
    "    y_changes.append(new_traj_y)\n",
    "    mmsis.append(first_mmsi)\n",
    "    mmsis.append(second_mmsi)\n",
    "    first_indexes.append(first_idx)\n",
    "    second_indexes.append(second_idx)\n",
    "    all_indexes.append(first_idx)\n",
    "    all_indexes.append(second_idx)\n",
    "    time_indexes_1.append(first_timestamp_index)\n",
    "    time_indexes_2.append(second_timestamp_index)\n",
    "\n",
    "for i,idx in enumerate(first_indexes):\n",
    "    X_test[idx,:,:] = X_changes[i]\n",
    "    y_test_copy[idx,:,:] = y_changes[i]\n",
    "\n",
    "X_test = X_test[:,:,2:]\n",
    "y_test_copy = y_test_copy[:,:,2:]\n",
    "\n",
    "y_test_copy = np.concatenate((y_test_copy,np.zeros((y_test_copy.shape[0],y_test_copy.shape[1],scaler.n_features_in_ - y_test_copy.shape[2]))),axis=2)\n",
    "y_test_copy = scaler.transform(y_test_copy.reshape(y_test_copy.shape[0]*y_test_copy.shape[1],y_test_copy.shape[2])).reshape((y_test_copy.shape[0],y_test_copy.shape[1],y_test_copy.shape[2]))\n",
    "y_test_copy = y_test_copy[:,:,:2]\n",
    "\n",
    "\n",
    "X_test = scaler.transform(X_test.reshape(X_test.shape[0]*X_test.shape[1],X_test.shape[2])).reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT RANDOM COLISSIONS\n",
    "mmsis  = [304776000.0, 210393000.0, 304146000.0, 245271000.0, 265413000.0, 259030000.0, 477587000.0, 636021860.0, 314418000.0, 255815000.0, 246000000.0, 244130641.0, 311379000.0, 255805594.0, 255815000.0, 255989000.0, 314500000.0, 244140468.0, 538006410.0, 255805577.0]\n",
    "first_indexes = [10149, 7141, 2348, 4980, 10218, 1372, 1149, 2351, 4576, 9205]\n",
    "second_indexes = [9876, 4438, 5087, 2156, 10050, 2538, 532, 8929, 9491, 3898]\n",
    "all_indexes  = [10149, 9876, 7141, 4438, 2348, 5087, 4980, 2156, 10218, 10050, 1372, 2538, 1149, 532, 2351, 8929, 4576, 9491, 9205, 3898]\n",
    "time_indexes_1  = [2, 2, 3, 3, 2, 1, 3, 2, 2, 2]\n",
    "time_indexes_2  = [4, 12, 4, 16, 16, 19, 17, 13, 14, 6]\n",
    "\n",
    "X_changes = []\n",
    "y_changes = []\n",
    "for i in range(len(first_indexes)):\n",
    "    print(i+1)\n",
    "    first_idx,second_idx,first_mmsi,second_mmsi,new_traj_X,new_traj_y,first_timestamp_index,second_timestamp_index = mockup_generator(X_test,y_test_copy,random_ship = False,ship_index1=first_indexes[i],ship_index2=second_indexes[i],timestamp_index1=time_indexes_1[i],timestamp_index2=time_indexes_2[i])\n",
    "    X_changes.append(new_traj_X)\n",
    "    y_changes.append(new_traj_y)\n",
    "\n",
    "\n",
    "for i,idx in enumerate(first_indexes):\n",
    "    X_test[idx,:,:] = X_changes[i]\n",
    "    y_test_copy[idx,:,:] = y_changes[i]\n",
    "\n",
    "    \n",
    "X_test = X_test[:,:,2:]\n",
    "y_test_copy = y_test_copy[:,:,2:]\n",
    "\n",
    "y_test_copy = np.concatenate((y_test_copy,np.zeros((y_test_copy.shape[0],y_test_copy.shape[1],scaler.n_features_in_ - y_test_copy.shape[2]))),axis=2)\n",
    "y_test_copy = scaler.transform(y_test_copy.reshape(y_test_copy.shape[0]*y_test_copy.shape[1],y_test_copy.shape[2])).reshape((y_test_copy.shape[0],y_test_copy.shape[1],y_test_copy.shape[2]))\n",
    "y_test_copy = y_test_copy[:,:,:2]\n",
    "\n",
    "\n",
    "X_test = scaler.transform(X_test.reshape(X_test.shape[0]*X_test.shape[1],X_test.shape[2])).reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2]))\n",
    "collisions = np.array([sorted(pair) for pair in zip(first_indexes, second_indexes)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mmsis  = {mmsis }')\n",
    "print(f'first_indexes = {first_indexes}')\n",
    "print(f'second_indexes = {second_indexes}')\n",
    "print(f'all_indexes  = {all_indexes }')\n",
    "print(f'time_indexes_1  = {time_indexes_1 }')\n",
    "print(f'time_indexes_2  = {time_indexes_2 }')\n",
    "# mmsis  = [304776000.0, 210393000.0, 304146000.0, 245271000.0, 265413000.0, 259030000.0, 477587000.0, 636021860.0, 314418000.0, 255815000.0, 246000000.0, 244130641.0, 311379000.0, 255805594.0, 255815000.0, 255989000.0, 314500000.0, 244140468.0, 538006410.0, 255805577.0]\n",
    "# first_indexes = [10149, 7141, 2348, 4980, 10218, 1372, 1149, 2351, 4576, 9205]\n",
    "# second_indexes = [9876, 4438, 5087, 2156, 10050, 2538, 532, 8929, 9491, 3898]\n",
    "# all_indexes  = [10149, 9876, 7141, 4438, 2348, 5087, 4980, 2156, 10218, 10050, 1372, 2538, 1149, 532, 2351, 8929, 4576, 9491, 9205, 3898]\n",
    "# time_indexes_1  = [2, 2, 3, 3, 2, 1, 3, 2, 2, 2]\n",
    "# time_indexes_2  = [4, 12, 4, 16, 16, 19, 17, 13, 14, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELLING\n",
    "\n",
    "def create_and_compile_model(model_type, layer_size,num_epochs,batch_size,n_features,available_models,test_number):\n",
    "    if model_type not in available_models:\n",
    "        print('No such model available, available models: ',available_models)\n",
    "        return \n",
    "    model_file_name = f'models/{model_type}-cells-{layer_size}-epochs-{num_epochs}-batch-{batch_size}-test-{test_number}-datetime-{datetime.today().strftime(\"%Y_%m_%d-%H_%M_%S\")}.h5'\n",
    "    history_file_name = f'models/{model_type}-cells-{layer_size}-epochs-{num_epochs}-batch-{batch_size}-{test_number}-datetime-{datetime.today().strftime(\"%Y_%m_%d-%H_%M_%S\")}-history.npy'\n",
    "    if model_type == 'GRU':\n",
    "        model = Sequential()\n",
    "        model.add(GRU(layer_size,activation='relu',input_shape=(seq_input_length,n_features)))\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(Dense(y_train_flat.shape[1],activation='relu'))\n",
    "    elif model_type == 'Bi_LSTM':\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(layer_size, activation='relu'), input_shape=(seq_input_length, n_features)))\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(Dense(y_train_flat.shape[1], activation='relu'))\n",
    "    elif model_type == 'LSTM':\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(layer_size, activation='relu', input_shape=(seq_input_length, n_features)))\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(Dense(y_train_flat.shape[1], activation='relu'))\n",
    "    elif model_type == 'LSTM_AE':\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(layer_size, activation='relu', input_shape=(seq_input_length, n_features)))\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(RepeatVector(seq_output_length))\n",
    "        model.add(LSTM(layer_size, activation='relu', return_sequences=False))\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(Dense(y_train_flat.shape[1], activation='relu'))\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, verbose=0,patience=8, min_lr=0.000001)\n",
    "    checkpoint = ModelCheckpoint(model_file_name, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    history = model.fit(X_train, y_train_flat, epochs=num_epochs, batch_size=batch_size, verbose=1, validation_data=(X_val, y_val_flat), callbacks=[earlyStopping,reduce_lr,checkpoint])\n",
    "    np.save(history_file_name, history.history)\n",
    "    model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [100,200]\n",
    "num_epochs = 100\n",
    "batch_sizes = [64,128]\n",
    "n_features = X_train.shape[2]\n",
    "model_repeat_time = 1\n",
    "available_models = ['GRU','LSTM_AE','LSTM','Bi_LSTM']\n",
    "# available_models = ['Bi_LSTM']\n",
    "for test_number in range(model_repeat_time):\n",
    "    for model in available_models:\n",
    "        for layer_size in layer_sizes:\n",
    "            for batch_size in batch_sizes:\n",
    "                create_and_compile_model(model,layer_size,num_epochs,batch_size,n_features,available_models,test_number)\n",
    "\n",
    "# truksta tik bilstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictions start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict on y_test (10 different models)\n",
    "\n",
    "y_test = np.concatenate((np.zeros((y_test.shape[0], y_test.shape[1], X_test.shape[2] - y_test.shape[2])),y_test),axis=2)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(y_test.shape[0]*y_test.shape[1],y_test.shape[2]))[:,-2:]\n",
    "y_test = y_test.reshape((int(y_test.shape[0]/seq_output_length),seq_output_length,2))\n",
    "\n",
    "model_names = []\n",
    "predictions = []\n",
    "for model_name in os.listdir('D:\\Python\\master thesis\\master-thesis\\models'):\n",
    "    if '.h5' in model_name:\n",
    "        print(model_name)\n",
    "        model = load_model(f'D:\\Python\\master thesis\\master-thesis\\models\\{model_name}')\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_test= y_pred_test.reshape(y_pred_test.shape[0],y_test.shape[1],y_test.shape[2])\n",
    "\n",
    "        y_pred_test = np.concatenate((np.zeros((y_pred_test.shape[0], y_pred_test.shape[1], X_test.shape[2] - y_test.shape[2])),y_pred_test),axis=2)\n",
    "        y_pred_test = scaler.inverse_transform(y_pred_test.reshape(y_pred_test.shape[0]*y_pred_test.shape[1],y_pred_test.shape[2]))[:,-2:]\n",
    "        y_pred_test = y_pred_test.reshape((int(y_pred_test.shape[0]/seq_output_length),seq_output_length,2))\n",
    "        \n",
    "        model_names.append(model_name)\n",
    "        predictions.append(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictions data prep\n",
    "\n",
    "X_test = scaler.inverse_transform(X_test.reshape(X_test.shape[0]*X_test.shape[1],X_test.shape[2]))\n",
    "X_test = X_test.reshape((int(X_test.shape[0]/seq_input_length),seq_input_length,X_train.shape[2]))\n",
    "y_test = diff_to_coord(y_test,X_test)\n",
    "predictions_new = []\n",
    "for y_pred in predictions:\n",
    "    y_pred_test = diff_to_coord(y_pred,X_test)\n",
    "    predictions_new.append(y_pred_test)\n",
    "predictions = predictions_new\n",
    "\n",
    "y_test_new = np.concatenate((y_test_primary[:,:,:2],y_test),axis=2)\n",
    "X_test_new = np.concatenate((X_test_primary[:,:,:2],X_test),axis=2)\n",
    "predictions_new = []\n",
    "for i in predictions:\n",
    "    y_pred_test_new = np.concatenate((y_test_primary[:,:,:2],i),axis=2)\n",
    "    predictions_new.append(y_pred_test_new)\n",
    "predictions = predictions_new\n",
    "\n",
    "new_predictions= np.stack(predictions,axis=-1)\n",
    "centroids = np.concatenate([new_predictions[:,:,0:2,0],np.mean(new_predictions[:,:,2:4,:],axis=-1)],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if doesnt exist procceed with lower\n",
    "interactions = np.load('interactions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### interaction dataset prep, result - table with three columns : first sequence id, second sequence id, whether the interaction is collision.\n",
    "\n",
    "total_interactions = 0\n",
    "interactions = []\n",
    "for i in tqdm(range(X_test_new.shape[0])):\n",
    "    for j in range(X_test_new.shape[0]):\n",
    "        if j > i and X_test_new[i,0,0] != X_test_new[j,0,0] and not(X_test_new[i,-1,1] + np.timedelta64(19,'m') < X_test_new[j,-1,1] or X_test_new[j,-1,1] + np.timedelta64(19,'m') < X_test_new[i,-1,1]) and haversine_distance(X_test_new[i,-1,3],X_test_new[i,-1,2],X_test_new[j,-1,3],X_test_new[j,-1,2]) < 30.84:\n",
    "            total_interactions+=1\n",
    "            if np.any(np.all(collisions == [i,j],axis=1)):\n",
    "                interactions.append([i,j,1])\n",
    "            else:\n",
    "                interactions.append([i,j,0])\n",
    "                \n",
    "            \n",
    "print(total_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check\n",
    "\n",
    "sample = random.randint(0,X_test.shape[0] - 1)\n",
    "# sample = 1681\n",
    "for y_pred in predictions:\n",
    "    plt.plot(y_pred[sample,:,3],y_pred[sample,:,2])\n",
    "    # break\n",
    "plt.plot(X_test[sample,:,1],X_test[sample,:,0], color='red',label= 'start_path')\n",
    "plt.plot(y_test[sample,:,1],y_test[sample,:,0], color='blue',label= 'true_path')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize_ellipse(prediction_region,with_points=True,legend=True,label=True,vizualize=True): #Vizualizes bounding ellipse around a bi-variate cluster\n",
    "    t = np.linspace(0,2.0 * np.pi,1000)\n",
    "    xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "    covariance = np.cov(prediction_region[1,:].astype('float'),prediction_region[0,:].astype('float'))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "    val = np.sqrt(eigenvalues)\n",
    "    center = np.mean([prediction_region[1,:].astype('float'),prediction_region[0,:].astype('float')],axis=1)[:,None]\n",
    "    if vizualize:\n",
    "        if with_points:\n",
    "            plt.scatter(prediction_region[1,:],prediction_region[0,:],label='Predicted points',color='#1f77bd')\n",
    "            plt.scatter(center[0],center[1],label='Mean prediction',color='#ff7f0e')\n",
    "        if label:\n",
    "            plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),label='Predicted trajectory regions',color='#2ca02c')\n",
    "        else:\n",
    "            plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),color='#2ca02c')\n",
    "        # plt.plot(*(2.44765*eigenvectors @ (val * xy).T + center),label='95% confidence ellipse',color='#2ca02c')\n",
    "        if legend:\n",
    "            plt.legend(loc='upper right')\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        plt.gca().locator_params(nbins=5)\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "    else:\n",
    "        pass\n",
    "    return covariance,eigenvectors,val,eigenvalues,center\n",
    "\n",
    "def point_intersection(scatter1,scatter2,vizualize=False): # Calculates number of points intersecting with other scatter's ellipse and vice versa\n",
    "    # plt.scatter(scatter1[3,:],scatter1[2,:])\n",
    "    # # plt.scatter(scatter2[3,:],scatter2[2,:])\n",
    "    ## Point intersection\n",
    "    covariance1 = np.cov(scatter1[3,:].astype('float'),scatter1[2,:].astype('float'))\n",
    "    covariance2 = np.cov(scatter2[3,:].astype('float'),scatter2[2,:].astype('float'))\n",
    "    \n",
    "    eigenvalues1, eigenvectors1 = np.linalg.eig(covariance1)\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(covariance2)\n",
    "    val1 = np.sqrt(eigenvalues1)\n",
    "    val2 = np.sqrt(eigenvalues2)\n",
    "    center1 = np.mean([scatter1[3,:].astype('float'),scatter1[2,:].astype('float')],axis=1)[:,None]\n",
    "    center2 = np.mean([scatter2[3,:].astype('float'),scatter2[2,:].astype('float')],axis=1)[:,None]\n",
    "    intersection_points = 0\n",
    "    for point_idx in range(scatter1.shape[1]):\n",
    "        point1 = scatter1[2:4,point_idx]\n",
    "        point1 = np.flip(point1)\n",
    "        point2 = scatter2[2:4,point_idx]\n",
    "        point2 = np.flip(point2)\n",
    "        # plt.scatter(point[1],point[0])\n",
    "        if (point1 - center2.flatten()) @ (np.linalg.inv((5.991)*covariance2)) @ (point1 - center2.flatten()) < 1:\n",
    "            intersection_points += 1 #skaiciuojam ar point in ar out ellipse \n",
    "            plt.scatter(point1[0],point1[1],color='red')\n",
    "        if (point2 - center1.flatten()) @ (np.linalg.inv((5.991)*covariance1)) @ (point2 - center1.flatten()) < 1:\n",
    "            intersection_points += 1 #skaiciuojam ar point in ar out ellipse\n",
    "            plt.scatter(point2[0],point2[1],color='red')\n",
    "    if intersection_points > 0 and vizualize == True:\n",
    "        vizualize_ellipse(scatter1[2:4,:],True,False,False)\n",
    "        vizualize_ellipse(scatter2[2:4,:],True,False,False)\n",
    "    return intersection_points\n",
    "\n",
    "def ellipsoidal_area_intersection(scatter1,scatter2): # calculates intersection area of two ellipses that bounds two scatters\n",
    "    covariance1 = np.cov(scatter1[3,:].astype('float'),scatter1[2,:].astype('float'))\n",
    "    covariance2 = np.cov(scatter2[3,:].astype('float'),scatter2[2,:].astype('float'))\n",
    "    eigenvalues1, eigenvectors1 = np.linalg.eig(covariance1)\n",
    "    eigenvalues2, eigenvectors2 = np.linalg.eig(covariance2)\n",
    "    val1 = np.sqrt(eigenvalues1)\n",
    "    val2 = np.sqrt(eigenvalues2)\n",
    "    center1 = np.mean([scatter1[3,:].astype('float'),scatter1[2,:].astype('float')],axis=1)[:,None]\n",
    "    center2 = np.mean([scatter2[3,:].astype('float'),scatter2[2,:].astype('float')],axis=1)[:,None]\n",
    "    ellipse1 = 2.44765*eigenvectors1 @ (val1 * xy).T + center1\n",
    "    ellipse2 = 2.44765*eigenvectors2 @ (val2 * xy).T + center2\n",
    "    polygon1 = Polygon(ellipse1.T)\n",
    "    polygon2 = Polygon(ellipse2.T)\n",
    "    intersection = polygon1.intersection(polygon2)\n",
    "    if not intersection.is_empty:\n",
    "        \n",
    "        intersection_area = intersection.area\n",
    "        # print(f\"The area of intersection is: {intersection_area}\")\n",
    "        # print(f\"Intersection percentage {round((intersection_area*100)/(polygon1.area + polygon2.area - intersection_area),2)}%\")\n",
    "        iou = (intersection_area*100)/(polygon1.area + polygon2.area - intersection_area)\n",
    "        intersection_x,intersection_y = intersection.exterior.xy\n",
    "        plt.fill(intersection_x,intersection_y,alpha=0.4,color='y')\n",
    "        \n",
    "        # inset_position = [0.65, 0.65, 0.25, 0.25]  # [left, bottom, width, height] in figure coordinates\n",
    "        # inset_ax = plt.axes(inset_position)  # Create inset axes\n",
    "        # inset_ax.ticklabel_format(useOffset=False)\n",
    "        # inset_ax.fill(intersection_x,intersection_y,alpha=0.4,color='y')\n",
    "        # inset_ax.set_xlim(12.2139, 12.2142)\n",
    "        # inset_ax.set_ylim(54.5513, 54.5514)\n",
    "        # # inset_ax.set_xticklabels([])\n",
    "        # inset_ax.set_title(\"Zoomed in intersection\", fontsize=10)\n",
    "        # inset_ax.tick_params(labelsize=8)  # Smaller ticks for inset\n",
    "\n",
    "        return intersection.area,iou\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def z_score_bounding_box(vessel_cluster, z_score):\n",
    "    vessel1_long_m,vessel1_lat_m = np.mean([vessel_cluster[3,:],vessel_cluster[2,:]],axis=1)\n",
    "    vessel1_long_std,vessel1_lat_std = np.std(np.array(vessel_cluster[3,:])),np.std(np.array(vessel_cluster[2,:]))\n",
    "    \n",
    "    vessel1_long_lim_min = vessel1_long_m  - vessel1_long_std*z_score\n",
    "    vessel1_long_lim_max = vessel1_long_m  + vessel1_long_std*z_score\n",
    "    vessel1_lat_lim_min = vessel1_lat_m  - vessel1_lat_std*z_score\n",
    "    vessel1_lat_lim_max = vessel1_lat_m  + vessel1_lat_std*z_score\n",
    "    coord1 = [vessel1_long_lim_min,vessel1_lat_lim_min]\n",
    "    coord2 = [vessel1_long_lim_min,vessel1_lat_lim_max]\n",
    "    coord3 = [vessel1_long_lim_max,vessel1_lat_lim_max]\n",
    "    coord4 = [vessel1_long_lim_max,vessel1_lat_lim_min]\n",
    "    square_coord = np.vstack((coord1,coord2,coord3,coord4,coord1)).T\n",
    "    return square_coord\n",
    "\n",
    "def square_intersection_area(square1,square2):\n",
    "    sq1_b_l =np.min(square1,axis=1)\n",
    "    sq1_t_r= np.max(square1,axis=1)\n",
    "    sq2_b_l =np.min(square2,axis=1)\n",
    "    sq2_t_r= np.max(square2,axis=1)\n",
    "    x_l = max(sq1_b_l[0],sq2_b_l[0])\n",
    "    y_b = max(sq1_b_l[1],sq2_b_l[1])\n",
    "    x_r = min(sq1_t_r[0],sq2_t_r[0])\n",
    "    y_t = min(sq1_t_r[1],sq2_t_r[1])\n",
    "    coord1 = [x_l,y_b]\n",
    "    coord2 = [x_l,y_t]\n",
    "    coord3 = [x_r,y_t]\n",
    "    coord4 = [x_r,y_b]\n",
    "    if x_l < x_r and y_b < y_t:\n",
    "        width = x_r - x_l\n",
    "        height = y_t - y_b\n",
    "        area = width * height\n",
    "        sq1_area = (sq1_t_r[0] - sq1_b_l[0]) * (sq1_t_r[1] - sq1_b_l[1])\n",
    "        sq2_area = (sq2_t_r[0] - sq2_b_l[0]) * (sq2_t_r[1] - sq2_b_l[1])\n",
    "        iou = area/(sq1_area+sq2_area-area)\n",
    "        intersect_coords = np.vstack((coord1,coord2,coord3,coord4,coord1)).T\n",
    "        return area,iou,intersect_coords\n",
    "    else:\n",
    "        # print('Squares do not intersect')\n",
    "        return 0,0,[]\n",
    "    \n",
    "def gmm(scatter1,scatter2,plot_gmm=True): #Creates GMM framework to vizualize and calculate GMM intersection area\n",
    "    np.random.seed(1)\n",
    "    cluster_1 = scatter1[2:4].T  # Cluster 1 (centered at [-2, -2])\n",
    "    cluster_2 = scatter2[2:4].T    # Cluster 2 (centered at [2, 2])\n",
    "\n",
    "    # # Combine the clusters into one array\n",
    "    data = np.vstack([cluster_1, cluster_2])\n",
    "    df = pd.DataFrame(data, columns=['Latitude', 'Longitude'])\n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=42)\n",
    "    gmm.fit(data)\n",
    "    labels = gmm.predict(data)  # Cluster assignments\n",
    "    labels = np.array([0] * 10 + [1] * 10)\n",
    "    df['Cluster'] = labels\n",
    "    if plot_gmm:\n",
    "        g = sns.JointGrid(data=df, x='Longitude', y='Latitude')\n",
    "        g.ax_joint.ticklabel_format(useOffset=False)\n",
    "\n",
    "        # Add scatter points for each cluster with different colors\n",
    "        colors = ['red', 'blue']\n",
    "        for cluster_id, color in enumerate(colors):\n",
    "            cluster_data = df[df['Cluster'] == cluster_id]\n",
    "            g.ax_joint.scatter(\n",
    "                cluster_data['Longitude'],\n",
    "                cluster_data['Latitude'],\n",
    "                label=f'Cluster {cluster_id + 1}',\n",
    "                color=color,\n",
    "                s=20,\n",
    "                alpha=1\n",
    "        )\n",
    "\n",
    "    kde1_long = gaussian_kde(np.array(cluster_1[:,1],dtype='float'))\n",
    "    kde2_long = gaussian_kde(np.array(cluster_2[:,1],dtype='float'))\n",
    "    kde1_lat = gaussian_kde(np.array(cluster_1[:,0],dtype='float'))\n",
    "    kde2_lat = gaussian_kde(np.array(cluster_2[:,0],dtype='float'))\n",
    "\n",
    "    x_long = np.linspace(min(min(cluster_1[:,1]), min(cluster_2[:,1]))-0.001, max(max(cluster_1[:,1]), max(cluster_2[:,1]))+0.001, 1000)\n",
    "    x_lat = np.linspace(min(min(cluster_1[:,0]), min(cluster_2[:,0]))-0.001, max(max(cluster_1[:,0]), max(cluster_2[:,0]))+0.001, 1000)\n",
    "\n",
    "\n",
    "\n",
    "    kde1_values_long = kde1_long(x_long)\n",
    "    kde2_values_long = kde2_long(x_long)\n",
    "\n",
    "    kde1_values_lat = kde1_lat(x_lat)\n",
    "    kde2_values_lat = kde2_lat(x_lat)\n",
    "    if plot_gmm:\n",
    "        g.ax_marg_x.plot(x_long, kde1_values_long, label='Cluster Data 1', lw=2,color=colors[0])\n",
    "        g.ax_marg_x.plot(x_long, kde2_values_long, label='Cluster Data 2', lw=2,color=colors[1])\n",
    "        g.ax_marg_x.fill_between(x_long, kde1_values_long, alpha=0.2, label='Intersection',color='red')\n",
    "        g.ax_marg_x.fill_between(x_long, kde2_values_long, alpha=0.2, label='Intersection',color='blue')\n",
    "        g.ax_marg_x.fill_between(x_long, np.minimum(kde1_values_long, kde2_values_long), alpha=0.5, label='Intersection',color='yellow')\n",
    "\n",
    "        g.ax_marg_y.plot(kde1_values_lat,x_lat, label='Cluster Data 1', lw=2,color=colors[0])\n",
    "        g.ax_marg_y.plot(kde2_values_lat,x_lat, label='Cluster Data 2', lw=2,color=colors[1])\n",
    "        g.ax_marg_y.fill_betweenx(x_lat,kde1_values_lat, alpha=0.2, label='Intersection',color='red')\n",
    "        g.ax_marg_y.fill_betweenx(x_lat,kde2_values_lat, alpha=0.2, label='Intersection',color='blue')\n",
    "        g.ax_marg_y.fill_betweenx(x_lat,np.minimum(kde1_values_lat, kde2_values_lat), alpha=0.5, label='Intersection',color='yellow')\n",
    "    \n",
    "    intersection_area_long = np.trapz(np.minimum(kde1_values_long, kde2_values_long), x_long)\n",
    "    intersection_area_lat = np.trapz(np.minimum(kde1_values_lat, kde2_values_lat), x_long)\n",
    "    if plot_gmm:\n",
    "        print(f\"Longitude intersection area {intersection_area_long}\")\n",
    "        print(f\"Latitude intersection area {intersection_area_lat}\")\n",
    "        print(f\"Intersection area multiplied {intersection_area_long*intersection_area_lat}\")\n",
    "        print('------')\n",
    "        plt.show()\n",
    "    return intersection_area_long*intersection_area_lat\n",
    "def n_root(x,n):\n",
    "    return x**(1./n)    \n",
    "def n_logistic(x,n):\n",
    "    return (1-(1./(1+math.e**(n*(x-0.5)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELLIPSOIDAL POINT INTERSECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.ticklabel_format(useOffset=False) # Not using scientific notation\n",
    "t = np.linspace(0,2.0 * np.pi,1000) # Helper datasets for building vizualiziations\n",
    "xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "for interaction in tqdm(interactions):\n",
    "    plt.plot(X_test_new[interaction[0],:,3],X_test_new[interaction[0],:,2]) #first ship predictor\n",
    "\n",
    "    plt.plot(X_test_new[interaction[1],:,3],X_test_new[interaction[1],:,2]) #second ship predictor\n",
    "    \n",
    "    intersection = np.intersect1d(y_test_new[interaction[0],:,1],y_test_new[interaction[1],:,1]) # only data where timepoints match on an interaction\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    collision_counter = 0\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        plt.gca().locator_params(nbins=5)\n",
    "\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:] \n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "\n",
    "        covariance1,eigenvectors1,val1,eigenvalues1,center1 = vizualize_ellipse(scatter1[2:4,:],False,False,False,False)\n",
    "        covariance2,eigenvectors2,val2,eigenvalues2,center2 = vizualize_ellipse(scatter2[2:4,:],False,False,False,False)\n",
    "\n",
    "        plt.plot(*(2.44765*eigenvectors1 @ (val1 * xy).T + center1),color=palette[i])\n",
    "        plt.plot(*(2.44765*eigenvectors2 @ (val2 * xy).T + center2),color=palette[i])\n",
    "        intersection_points = point_intersection(scatter1,scatter2,False)\n",
    "        # print(intersection_points)\n",
    "        \n",
    "\n",
    "        plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red') # first vessel target variable\n",
    "        plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange') # second vessel target variable\n",
    "        plt.show() # comment out if all prediction regions wanted to be seen together\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELLIPSOIDAL AREA INTERSECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.ticklabel_format(useOffset=False)\n",
    "t = np.linspace(0,2.0 * np.pi,1000)\n",
    "xy = np.stack((np.cos(t),np.sin(t)),axis=-1)\n",
    "for interaction in tqdm(interactions):\n",
    "    plt.plot(X_test_new[interaction[0],:,3],X_test_new[interaction[0],:,2]) #first ship predictor\n",
    "\n",
    "    plt.plot(X_test_new[interaction[1],:,3],X_test_new[interaction[1],:,2]) #second ship predictor\n",
    "    \n",
    "    intersection = np.intersect1d(y_test_new[interaction[0],:,1],y_test_new[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        covariance1,eigenvectors1,val1,eigenvalues1,center1 = vizualize_ellipse(scatter1[2:4,:],False,False,False,False)\n",
    "        covariance2,eigenvectors2,val2,eigenvalues2,center2 = vizualize_ellipse(scatter2[2:4,:],False,False,False,False)\n",
    "        plt.plot(*(2.44765*eigenvectors1 @ (val1 * xy).T + center1),color=palette[i])\n",
    "        plt.plot(*(2.44765*eigenvectors2 @ (val2 * xy).T + center2),color=palette[i])\n",
    "        plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red')\n",
    "        plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange')\n",
    "        area,iou = ellipsoidal_area_intersection(scatter1,scatter2)\n",
    "        print(area,iou)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-SCORE INTERSECTION AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    intersection = np.intersect1d(y_test_new[interaction[0],:,1],y_test_new[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        plt.ticklabel_format(useOffset=False)\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        plt.scatter(scatter1[3,:],scatter1[2,:],color=palette[i],alpha=0.5)\n",
    "        plt.scatter(scatter2[3,:],scatter2[2,:],color=palette[i],alpha=0.5)\n",
    "        square_coord1 = z_score_bounding_box(scatter1,3)\n",
    "        square_coord2 = z_score_bounding_box(scatter2,3)\n",
    "        area, iou,intersect_coords= square_intersection_area(square_coord1,square_coord2)\n",
    "        plt.scatter(y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='red')\n",
    "        plt.scatter(y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],3],y_test_new[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],2],color='orange')\n",
    "        print(area,iou)\n",
    "        plt.plot(square_coord1[0],square_coord1[1],color=palette[i])\n",
    "        plt.plot(square_coord2[0],square_coord2[1],color=palette[i])\n",
    "        if area > 0:\n",
    "            plt.fill(intersect_coords[0],intersect_coords[1],color = 'y',alpha= 0.3)\n",
    "        plt.show()        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_interactions = []\n",
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    intersection = np.intersect1d(y_test_new[interaction[0],:,1],y_test_new[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    highest_per_interaction = 0\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        score = gmm(scatter1,scatter2)\n",
    "        if score > highest_per_interaction:\n",
    "            highest_per_interaction = score\n",
    "    gmm_interactions.append([highest_per_interaction,interaction[2]]) ## dataset with all highest score of GMM per interaction + showing whether its collision\n",
    "gmm_interactions = np.array(gmm_interactions)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gmm_interactions[np.where(gmm_interactions[:,1] == 1),0],gmm_interactions[np.where(gmm_interactions[:,1] == 1),1])\n",
    "plt.scatter(gmm_interactions[np.where(gmm_interactions[:,1] == 0),0],gmm_interactions[np.where(gmm_interactions[:,1] == 0),1])\n",
    "plt.xlabel('GMM intersection score')\n",
    "plt.ylabel('Collision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SILHOUETTE VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_interactions = []\n",
    "for interaction in tqdm(interactions):\n",
    "\n",
    "    intersection = np.intersect1d(y_test_new[interaction[0],:,1],y_test_new[interaction[1],:,1])\n",
    "    palette = sns.color_palette(\"viridis_r\", len(intersection))\n",
    "    lowest_per_interaction = 1\n",
    "    for i,timepoint in enumerate(intersection):\n",
    "        scatter1 = new_predictions[interaction[0],np.where(np.all(new_predictions[interaction[0],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        scatter2 = new_predictions[interaction[1],np.where(np.all(new_predictions[interaction[1],:,1,:] == timepoint,axis=1)==True)[0][0],:,:]\n",
    "        cluster1_points = scatter1[2:4,:].T\n",
    "        cluster2_points = scatter2[2:4,:].T\n",
    "        combined_data = np.vstack([cluster1_points, cluster2_points])\n",
    "        labels = np.array([0] * cluster1_points.shape[0] + [1] * cluster2_points.shape[0])\n",
    "        silhouette_avg = silhouette_score(combined_data, labels)\n",
    "        if silhouette_avg < lowest_per_interaction:\n",
    "            lowest_per_interaction = silhouette_avg\n",
    "    silhouette_interactions.append([1-lowest_per_interaction,interaction[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_silhouette_interactions = []\n",
    "logistic_silhouette_interactions = []\n",
    "for i in silhouette_interactions:\n",
    "    root_silhouette_interactions.append([n_root(i[0],2),i[1]])\n",
    "for i in silhouette_interactions:\n",
    "    logistic_silhouette_interactions.append([n_logistic(i[0],10),i[1]])\n",
    "root_silhouette_interactions = np.array(root_silhouette_interactions)\n",
    "logistic_silhouette_interactions = np.array(logistic_silhouette_interactions)\n",
    "sns.kdeplot(x=root_silhouette_interactions[:,0], fill=True, color='blue', bw_adjust=0.2)\n",
    "plt.xlabel('Silhouette score square root transformation')\n",
    "plt.show()\n",
    "sns.kdeplot(x=logistic_silhouette_interactions[:,0], fill=True, color='blue', bw_adjust=0.2)\n",
    "plt.xlabel('Silhouette score logistic (n=10) transformation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
